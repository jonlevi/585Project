{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import scipy as sp\n",
    "import random\n",
    "from model_scratch_rbf import RBFNetwork\n",
    "from sklearn.datasets import load_digits\n",
    "from scipy.spatial.distance import euclidean\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def test_wrapper(NUMBER_TO_TRAIN):\n",
    "    \n",
    "    n_loops = 5\n",
    "    \n",
    "    # test performance with varying centers\n",
    "    scores = []\n",
    "    for n_centers in range(1,21):\n",
    "        sensitivities = [run_recognition(NUMBER_TO_TRAIN, n_centers) for i in range(n_loops)]\n",
    "        scores.append(sensitivities)\n",
    "    scores_center = np.array(scores)\n",
    "\n",
    "    return scores_center\n",
    "\n",
    "def run_recognition(NUMBER_TO_TRAIN, n_centers):\n",
    "    \n",
    "    # Set parameters\n",
    "    n_in = 64\n",
    "    n_out = 64\n",
    "    learning_rate = 1\n",
    "    beta = .5\n",
    "    train_size = 40\n",
    "    n_training_iter = 1\n",
    "\n",
    "    # Load handwritten digit dataset, normalize values (from 0-16 to 0-1), and shuffle order\n",
    "    all_images, digits = load_digits(n_class=10, return_X_y=True)\n",
    "    all_images = all_images / 16\n",
    "    indx = [i for i in range(len(all_images))]\n",
    "    random.shuffle(indx)\n",
    "    all_images = all_images[indx]\n",
    "    digits = digits[indx]\n",
    "\n",
    "    # Group images by their digits\n",
    "    zeros = all_images[digits==0]\n",
    "    ones = all_images[digits==1]\n",
    "    twos = all_images[digits==2]\n",
    "    threes = all_images[digits==3]\n",
    "    fours = all_images[digits==4]\n",
    "    fives = all_images[digits==5]\n",
    "    sixes = all_images[digits==6]\n",
    "    sevens = all_images[digits==7]\n",
    "    eights = all_images[digits==8]\n",
    "    nines = all_images[digits==9]\n",
    "    all_images = [zeros, ones, twos, threes, fours, fives, sixes, sevens, eights, nines]\n",
    "\n",
    "    # Initialize model\n",
    "    standard_view = np.mean(all_images[NUMBER_TO_TRAIN], axis=0)\n",
    "    target_funcs = [(lambda i: standard_view[i]) for x in range(len(standard_view))]\n",
    "    n = RBFNetwork(n_in=n_in,\n",
    "                   n_hidden=n_centers,\n",
    "                   n_out=n_out,\n",
    "                   lr=learning_rate,\n",
    "                   h_funcs=target_funcs,\n",
    "                   beta=beta)\n",
    "\n",
    "    # Split data into training and test sets and run training\n",
    "    imgs = all_images[NUMBER_TO_TRAIN]\n",
    "    train_set = imgs[:train_size]\n",
    "    test_set = imgs[train_size:]\n",
    "    n.centers = train_set[:n_centers]\n",
    "    v = n.train(train_set, n_iter=n_training_iter)\n",
    "\n",
    "    # Test on all images that were not used for training\n",
    "    predicted_imgs = [None for i in range(10)]\n",
    "    activation = [None for i in range(10)]\n",
    "    distances = [None for i in range(10)]\n",
    "    for i in range(10):\n",
    "        if i == NUMBER_TO_TRAIN:\n",
    "            predicted_imgs[i] = np.array([n.activate(img) for img in test_set])\n",
    "        else:\n",
    "            predicted_imgs[i] = np.array([n.activate(img) for img in all_images[i]])\n",
    "        activation[i] = np.max(predicted_imgs[i], axis=1)\n",
    "        distances[i] = [euclidean(img, standard_view) for img in predicted_imgs[i]]\n",
    "\n",
    "    # determine recognition threshold by training activations\n",
    "    train_activation = [n.activate(img) for img in train_set]\n",
    "    threshold = np.min([np.max(x) for x in train_activation])\n",
    "    response = [x >= threshold for x in activation]\n",
    "\n",
    "    # Calculate the percent of the time the model responds \"yes\" to each digit type\n",
    "    percent_yes = [x.mean() for x in response]\n",
    "    # print(percent_yes)\n",
    "\n",
    "    # calculate hit and false alarm rate\n",
    "    this_number_test_response = response[NUMBER_TO_TRAIN]\n",
    "    hit_rate = np.mean(this_number_test_response)\n",
    "    other_numbers_test_response = []\n",
    "    for i in range(10):\n",
    "        if i!=NUMBER_TO_TRAIN:\n",
    "            other_numbers_test_response = other_numbers_test_response + response[i].tolist()\n",
    "    fa_rate = np.mean(other_numbers_test_response)\n",
    "    sensitivity = hit_rate - fa_rate\n",
    "\n",
    "    print ('hit rate=%0.3f   fa rate=%0.3f' % (hit_rate, fa_rate))\n",
    "    print ('sensitivity=%0.3f'% sensitivity)\n",
    "\n",
    "    return sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(2) as p:\n",
    "    scores_center = p.map(test_wrapper, range(10))\n",
    "scores_center = np.array(scores_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save('scores_center_100loops.npy', scores_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance with varying centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scores_center = np.load('scores_center_100loops.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=[10,6])\n",
    "\n",
    "colors=['C5','C3','C1','C8','C2','C9','C0','C4','C6','C7']\n",
    "\n",
    "for i in range(10):\n",
    "    x = range(1,21)\n",
    "    values = scores_center[i]\n",
    "    err = sp.stats.sem(values, axis=1)\n",
    "    ax.plot(x, values.mean(1), label='train digit=%d'%i, color=colors[i])\n",
    "    ax.fill_between(x, values.mean(1)-err, values.mean(1)+err, color=colors[i], alpha=0.3)\n",
    "    \n",
    "# ax.plot(x, scores.mean(2).mean(0))\n",
    "    \n",
    "ax.set_xticks(x[::3])\n",
    "ax.legend(ncol=2)\n",
    "ax.set_ylim([0,1])\n",
    "\n",
    "ax.set_ylabel('Sensitivity')\n",
    "ax.set_xlabel('N Centers')\n",
    "\n",
    "# fig.savefig('varying_centers_100loops.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
